Supplementary Material for
Differentially Private Bayesian Optimization

Matt J. Kusner
Jacob R. Gardner
Roman Garnett
Kilian Q. Weinberger
Washington University in St. Louis, 1 Brookings Dr., St. Louis, MO 63130

Here we give the omitted proofs of intermediate results
left out of the main paper.

With observation noise
Proof of Corollary 1.
Let V, V 0 be neighboring
datasets. Let E denote the event that the global sensitivity bound of Theorem 1 holds. Thus, Pr[E] â‰¥ 1 âˆ’ Î´.
If E holds, drawing
p Î»Ìƒ with probability proportional to
exp(ÂµT (Î»)/(4 Î²T +1 + 2c)) is -differentially private
by the privacy guarantee of the exponential mechanism
(McSherry & Talwar, 2007). Specifically, the inequality holds: Pr[A(V) = Î»Ìƒ(T ) |E] â‰¤ e Pr[A(V 0 ) = Î»Ìƒ|E].
We demonstrate this implies (, Î´)-differential privacy,

et al., 2012) with probability at least 1 âˆ’ 2Î´ . Observe
the similarity of the above expression to eq. (6) (with
maxtâ‰¤T f (Î»t ) replaced with f (Î»T )). In fact, the remainder of this proof follows in nearly the same way
as the proof of Theorem 3. The only differences are
(a) we use f (Î»T ) instead of the max term, (b) we use
the regret bound of de Freitas et al. (2012) and, (c) we
need not bound the maximum v as there is no noise.

Proof of Corollary 3. Given the sensitivity bound of
Theorem 5, the proof follows in the same way as the
proof of Corollary 2, where E is the event that Theorem 5 holds.

Proof of Theorem 6. For a random variable Z âˆ¼
Lap(b), recall that Pr[|Z| â‰¤ ab] = 1 âˆ’ eâˆ’a . ThereËœ
fore, as defined
 in Algorithm 2, |f âˆ’ f (Î»T )| â‰¤ ab for

Pr[A(V) = Î»Ìƒ]
â‰¤ Pr[A(V) = Î»Ìƒ|E]Pr[E] + 1 âˆ’ Pr[E]

mkusner@wustl.edu
gardner.jake@wustl.edu
garnett@wustl.edu
kilian@wustl.edu



â„¦


c


with probability 1 âˆ’ eâˆ’a . Note that,

â‰¤ e Pr[A(V 0 ) = Î»Ìƒ|E]Pr[E] + Î´

b =

â‰¤ e Pr[A(V 0 ) = Î»Ìƒ, E] + Î´

similar to eq. (7), we have for the noise-free setting,
ab â‰¥ f (Î»T ) âˆ’ fËœ â‰¥ (f (Î»âˆ— ) âˆ’ â„¦) âˆ’ fËœ

â‰¤ e Pr[A(V 0 ) = Î»Ìƒ] + Î´.

Proof of Corollary 2.
Let V, V 0 be neighboring
datasets. Again let E denote the event that the global
sensitivity of Theorem 3 holds (and thus Pr[E] â‰¥ 1 âˆ’
Î´). If E holds, adding Laplacian noise as as described
in Algorithm 1 to maxtâ‰¤T vt makes vÌƒ -differential
private, by the guarantee of the Laplace mechanism.
Specifically, the inequality holds: Pr[A(V) = vÌƒ|E] â‰¤
e Pr[A(V 0 ) = vÌƒ|E]. Using the same technique as the
proof of Corollary 1 it is straightforward to show that
vÌƒ is (, Î´)-differentially private.


Without observation noise
Proof of Theorem 5.

âˆ’

TÏ„
(log T )d/4

where the second inequality follows from the regret
bound of de Freitas et al. (2012) and holds w.p. at
least 1 âˆ’ Î´. This implies that f (Î»âˆ— ) âˆ’ fËœ â‰¤ â„¦ + ab.
We can use a similar analysis to eq. (8) to show that
f (Î»âˆ— ) âˆ’ fËœ â‰¥ âˆ’â„¦ âˆ’ ab. Therefore |fËœ âˆ’ f (Î»âˆ— )| â‰¤ â„¦ + ab
w.p. greater than 1 âˆ’ (Î´ + eâˆ’a ).


Without the GP assumption
Proof of Corollary 4. Given the total global sensitivity bound implied by Theorem 7, the proof is nearly
identical to the proof of Corollary 2, where E is the
event that the total global sensitivity holds.


References

Note that at time T the re-

gret is f (Î»âˆ— ) âˆ’ f (Î»T ) â‰¤ â„¦ , Ae

+

(de Freitas

de Freitas, Nando, Smola, Alex, and Zoghi, Masrour.
Exponential regret bounds for gaussian process ban-

Differentially Private Bayesian Optimization

dits with deterministic observations. In ICML, 2012.
Dwork, Cynthia, McSherry, Frank, Nissim, Kobbi, and
Smith, Adam. Calibrating noise to sensitivity in
private data analysis. In Theory of Cryptography,
pp. 265â€“284. Springer, 2006.
McSherry, Frank and Talwar, Kunal. Mechanism design via differential privacy. In FOCS, pp. 94â€“103.
IEEE, 2007.
Srinivas, Niranjan, Krause, Andreas, Kakade,
Sham M, and Seeger, Matthias. Gaussian process
optimization in the bandit setting: No regret and
experimental design. In ICML, 2010.

